# RoVF-Meerkat-Reidentification

This repository contains the codebase for **meerkat reidentification**, leveraging deep learning techniques to uniquely identify individual meerkats. The project uses image-based reidentification models and includes all necessary components for model training, evaluation, and analysis.

## Folder Structure

- **augmentations/**  
  Contains augmentation functions used for enhancing the training data. These functions improve model robustness by generating variations of the input images.

- **dataloaders/**  
  Data loaders for efficiently fetching and preparing data during training and inference. This directory defines how the data pipeline is structured.

- **evaluation/**  
  Scripts and utilities for evaluating the model performance, including metrics and visualizations. Results of the reidentification model are analyzed here.

- **figures/**  
  Contains generated figures and visualizations used to evaluate the performance and other aspects of the model.

- **get_anchors/**  
  Code for obtaining "anchor" embeddings, which serve as reference points in the reidentification task.

- **lr_schedulers/**  
  Learning rate scheduler configurations and implementations, designed to dynamically adjust the learning rate during training.

- **models/**  
  Code defining the architectures of various neural network models used in the project, including pre-trained or custom models for the reidentification task.

- **training_functions/**  
  Core functions required to train the models, including loss functions, optimization routines, and data pre-processing steps.

- **training_scripts/exp_metadata/**  
  Contains scripts and experiment metadata for training different image-based models. Useful for reproducing experiments and comparing results.

## Installation

To set up the environment, you can use the provided `setup_environment.py` script. This will install the necessary dependencies and configurations.

```bash
python setup_environment.py
```

## How to Run

TODO

## TODO

  - Improve this README. It is intially mostly generated by ChatGPT. 
  - Add segmentation code.
  - Fix instillation: some packages are not installed correctly.
  - Upload all trianing yaml files.
  - Update comments/documentation for all files.
  - Instruction on how to run main.py through the command line.
  - generate_yml.py should be updated to create all yaml file documents as well as results/ folder structure.
  - Instructions on how to set up Dataset/ folder (perhaps from downloadable links) and a bash script.
